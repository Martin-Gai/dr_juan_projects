---
title: "Introduction to BTYD (Buy Until You Die) Models"
subtitle: "Berlin Bayesians MeetUp - September 2022"
author: "Dr. Juan Orduz"
format:
  revealjs: 
    slide-number: false
    chalkboard: 
      buttons: false
    preview-links: auto
    theme:
        - "dark"
---

## Outline

::: incremental

1. Introduction to BTYD Models
2. BG/NBD Model: Model Specification
2. BG/NBD Model: Maximum Likelihood Estimation (`lifetimes`)
3. BG/NBD Model: Bayesian Estimation (`pymc`)
    
    - External Regressors
    - Hierarchical Model

4. References and Resources

:::

## Classifying Customer Bases

![](berlin_bayesians_btyd_files/images/square.png){fig-align="center"}

::: footer
See [Probability Models for Customer-Base Analysis](https://www.brucehardie.com/talks/ho_cba_tut_art_09.pdfl)
:::

## Purchase Histories

![](berlin_bayesians_btyd_files/images/purchase_histories.png){fig-align="center"}

::: footer
See [Probability Models for Customer-Base Analysis](https://www.brucehardie.com/talks/ho_cba_tut_art_09.pdfl)
:::

## The Pareto/NBD Model

![](berlin_bayesians_btyd_files/images/pareto_model_summary.png){fig-align="center"}

::: footer
[Counting Your Customers: Who Are They and What Will They Do Next?](https://www.jstor.org/stable/2631608) and [Probability Models for Customer-Base Analysis](https://www.brucehardie.com/talks/ho_cba_tut_art_09.pdf)
:::

## Models Workflow

```{mermaid}
%%{init: {"theme": "dark" } }%%
%%| fig-width: 10

flowchart LR
  A[Transaction Data] --> B(Transaction Model - BG/NBD)
  A --> C(Monetary Model - GG)
  B --> D[Probability of Alive]
  B --> E[Predicted Frequency]
  C --> F[Predicted Avg. Monetary Value]
  E --> G[Predicted CLV]
  F --> G[Predicted CLV]
```
- **Transaction Model:** Number of transactions per customer.
- **Monetary Model:** Average monetary value of a transaction.

## CLV Formula

[Discounted cash flow (DCF) method](https://en.wikipedia.org/wiki/Discounted_cash_flow):

$$
CLV = \sum_{i=1}^{\infty} \frac{M_i}{(1+\delta)^i}
$$

- $M_{i}$: cash flow in period $i$.
- $\delta$: discount rate.

```{.python}
for i in steps:
    df["clv"] += (
        (monetary_value * expected_number_of_transactions) 
        / (1 + discount_rate) ** i 
    )
```

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)
:::

## The BG/NBD Transaction Model

![](berlin_bayesians_btyd_files/images/bg_nbd_model_summary.png){fig-align="center"}

::: footer
[“Counting Your Customers” the Easy Way: An Alternative to the Pareto/NBD Model](http://brucehardie.com/papers/018/fader_et_al_mksc_05.pdf) and [Probability Models for Customer-Base Analysis](https://www.brucehardie.com/talks/ho_cba_tut_art_09.pdf)
:::

## Purchase Metrics

::: incremental

- `frequency`: Number of repeat purchases the customer has made. More precisely, It’s the count of time periods the customer had a purchase in.

- `T`: Age of the customer in whatever time units chosen. This is equal to the duration between a customer’s first purchase and the end of the period under study.

- `recency`: Age of the customer when they made their most recent purchases. This is equal to the duration between a customer’s first purchase and their latest purchase.

:::

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)
:::

## BG/NBD Assumptions (Frequency)

::: incremental

1. While active, the time between transactions is distributed exponential with transaction rate, i.e., 

    $$f(t_{j}|t_{j-1}; \lambda) = \lambda \exp(-\lambda (t_{j} - t_{j - 1})), \quad t_{j} \geq t_{j - 1} \geq 0$$ 

2. Heterogeneity in $\lambda$ follows a gamma distribution with pdf

    $$f(\lambda|r, \alpha) = \frac{\alpha^{r}\lambda^{r - 1}\exp(-\lambda \alpha)}{\Gamma(r)}, \quad \lambda  > 0$$

:::

::: footer
See [“Counting Your Customers” the Easy Way: An Alternative to the Pareto/NBD Model](http://brucehardie.com/papers/018/fader_et_al_mksc_05.pdf)
:::

## BG/NBD Assumptions (Dropout)

::: incremental

3. After any transaction, a customer becomes inactive with probability $p$.

4. Heterogeneity in $p$ follows a beta distribution with pdf

    $$f(p|a, b) = \frac{\Gamma(a + b)}{\Gamma(a) \Gamma(b)} p^{a - 1}(1 - p)^{b - 1}, \quad 0 \leq p \leq 1$$

5. The transaction rate $\lambda$ and the dropout probability $p$ vary independently across customers.

:::

::: footer
See [“Counting Your Customers” the Easy Way: An Alternative to the Pareto/NBD Model](http://brucehardie.com/papers/018/fader_et_al_mksc_05.pdf)
:::

## Likelihood: Easy to Compute!

$$
L(a, b, \alpha, r|X=x, t_x, T) = A_{1}A_{2}(A_{3} + \delta_{x>0}A_4)
$$

where

\begin{align*}
A_{1}  = \frac{\Gamma(r + x)\alpha^{{r}}}{\Gamma(x)}
\quad A_{2} & = \frac{\Gamma(a + b)\Gamma(b + x)}{\Gamma(b)\Gamma(a + b + x)} \\
A_{3} = \left(\frac{1}{\alpha + T}\right)^{r+x}
\quad A_{4} & = \left(\frac{a}{b + x - 1}\right)\left(\frac{1}{\alpha + t_x}\right)^{r + x}
\end{align*}

. . .

**Strategy:** Write this in [`numpy`](https://numpy.org/doc/stable/) as pass it through [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)

::: footer
See [BG/NBD Model for Customer Base Analysis in Excel](http://brucehardie.com/notes/004/bgnbd_spreadsheet_note.pdf) and [`lifetimes.BetaGeoFitter._negative_log_likelihood`](https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/fitters/beta_geo_fitter.py#L164)
:::

## Inference: [`lifetimes`](https://github.com/CamDavidsonPilon/lifetimes/) Package

The four BG/NBD model parameters can be estimated via the method of **maximum likelihood**.

``` {.python code-line-numbers="1-4|6|8-11|13-14"}
import numpy as np
import pandas as pd
from lifetimes.datasets import load_cdnow_summary
from lifetimes import BetaGeoFitter

data_df: pd.DataFrame = load_cdnow_summary(index_col=[0])

n = data_df.shape[0]
x = data_df["frequency"].to_numpy()
t_x = data_df["recency"].to_numpy()
T = data_df["T"].to_numpy()

bgf = BetaGeoFitter()
bgf.fit(frequency=x, recency=t_x, T=T)
```

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)
:::

## Predicted Future Purchases

``` {.python}
from lifetimes.plotting import plot_frequency_recency_matrix

ax = plot_frequency_recency_matrix(model=bgf, T=15)
```

![](berlin_bayesians_btyd_files/images/plot_frequency_recency_matrix_15.png){fig-align="center"}

$$E[Y(t) | X=x, t_x, T, r, \alpha, a , b]$$

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)
:::

## Probability of Alive

``` {.python}
from lifetimes.plotting import plot_probability_alive_matrix

ax = plot_probability_alive_matrix(model=bgf)
```

::: columns
::: {.column width="43.5%"}
![](berlin_bayesians_btyd_files/images/plot_probability_alive_matrix.png){fig-align="center"}
:::
::: {.column width="56.5%"}
![](berlin_bayesians_btyd_files/images/p_alive.png){fig-align="center"}
:::
:::

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html) and [Computing P(alive) Using the BG/NBD Model](https://brucehardie.com/notes/021/palive_for_BGNBD.pdf)
:::

## Probability of Alive

![](berlin_bayesians_btyd_files/images/p_alive_examples.png){fig-align="center"}

## Model Evaluation

::: columns
::: {.column width="47.5%"}
![](berlin_bayesians_btyd_files/images/plot_period_transactions.png){fig-align="center"}
:::
::: {.column width="52.5%"}
![](berlin_bayesians_btyd_files/images/plot_calibration_purchases_vs_holdout_purchases.png){fig-align="center"}
:::
:::

``` {.python}
summary["model_predictions"] = model.conditional_expected_number_of_purchases_up_to_time(
    duration_holdout, summary["frequency_cal"], summary["recency_cal"], summary["T_cal"]
)

summary.groupby("frequency_cal")[["frequency_holdout", "model_predictions"]].mean().plot()
```

::: footer
See [`lifetimes`: Quick Start](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)
:::

## From Numpy to Aesara

We can re-write the [`numpy`](https://numpy.org/doc/stable/) likelihood implementation in [`aesara`](https://github.com/aesara-devs/aesara).

![](berlin_bayesians_btyd_files/images/aesara_logo.png){fig-align="center"}

::: footer
See [Intro notebook: PyMC and Aesara](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_aesara.html)
:::

## Log-Likelihood in Aesara

The translation bewtween `numpy` and `aesara` is very easy (replace `np` by `at`)!


``` {.python }
import aesara.tensor as at


def logp(x, t_x, T, x_zero):
    a1 = at.gammaln(r + x) - at.gammaln(r) + r * at.log(alpha)
    a2 = (
        at.gammaln(a + b)
        + at.gammaln(b + x)
        - at.gammaln(b)
        - at.gammaln(a + b + x)
    )
    a3 = -(r + x) * at.log(alpha + T)
    a4 = (
        at.log(a) - at.log(b + at.maximum(x, 1) - 1) - (r + x) * at.log(t_x + alpha)
    )
    max_a3_a4 = at.maximum(a3, a4)
    ll_1 = a1 + a2
    ll_2 = (
        at.log(
            at.exp(a3 - max_a3_a4)
            + at.exp(a4 - max_a3_a4) * pm.math.switch(x_zero, 1, 0)
        )
        + max_a3_a4
    )
    return at.sum(ll_1 + ll_2)
```

## BG/NBD PyMC Model

### Model Structure

``` {.python code-line-numbers="1|2|5|7-11|13-14|16-19"}
import pymc as pm
import pymc.sampling_jax


with pm.Model() as model:

    a = pm.HalfNormal(name="a", sigma=10)
    b = pm.HalfNormal(name="b", sigma=10)

    alpha = pm.HalfNormal(name="alpha", sigma=10)
    r = pm.HalfNormal(name="r", sigma=10)

    def logp(x, t_x, T, x_zero):
        ...

    likelihood = pm.Potential(
        name="likelihood",
        var=logp(x=x, t_x=t_x, T=T, x_zero=x_zero),
    )
```

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::


## Model Sampling

```{.python}
with model:
    trace = pm.sampling_jax.sample_numpyro_nuts(
        tune=3000, draws=6000, chains=4,target_accept=0.95
)
```

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_25_0.png){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Probability of Active

**How?** Simply use the posterior samples ([`xarray`](https://docs.xarray.dev/en/stable/)) and broadcast the `numpy` expressions.

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_34_1.png){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Future Purchases

Similarty, using the analytical expressions:

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_42_0.png){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Time-Independent Covariates?

- Allow covariates $z_1$ and $z_2$ to explain the cross-sectional heterogeneity in the purchasing process and cross-sectional heterogeneity in the dropout process respectively.

- The likelihood and quantities of interests computed by computing expectations, remain almost the same. One only has to replace:

\begin{align*}
\alpha & \longmapsto \alpha_{0}\exp(-\gamma_{1}^{T}z_{1}) \\
a & \longmapsto a_{0}\exp(\gamma_{2}^{T}z_{2}) \\
b & \longmapsto b_{0}\exp(\gamma_{3}^{T}z_{2})
\end{align*}

::: footer
See [Incorporating Time-Invariant Covariates into the Pareto/NBD and BG/NBD Models](http://brucehardie.com/notes/019/time_invariant_covariates.pdf) and [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Simulated Example

```{.python code-line-numbers="3-6|8-9|11-13|15-17"}
np.random.seed(42)

# construct covariate
mu = 0.4
rho = 0.7
z = np.random.binomial(n=1, p=mu, size=x.size)

# change frequency values by reducing it the values where z !=0
x_z = np.floor(x * (1 - (rho * z)))

# make sure the recency is zero whenever the frequency is zero
t_x_z = t_x.copy()
t_x_z[np.argwhere(x_z == 0).flatten()] = 0

# sanity checks
assert x_z.min() == 0
assert np.all(t_x_z[np.argwhere(x_z == 0).flatten()] == 0)
```
. . .

$z = 1 \Rightarrow$ the frequency is reduced by $70\%$.

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## PyMC Model

```{.python code-line-numbers="6-8"}
with pm.Model() as model_cov:

    a = pm.HalfNormal(name="a", sigma=10)
    b = pm.HalfNormal(name="b", sigma=10)

    alpha0 = pm.HalfNormal(name="alpha0", sigma=10)
    g1 = pm.Normal(name="g1", mu=0, sigma=10)
    alpha = pm.Deterministic(name="alpha", var=alpha0 * at.exp(- g1 * z))
    
    r = pm.HalfNormal(name="r", sigma=10)

    def logp(x, t_x, T, x_zero):
        ...

    likelihood = pm.Potential(
        name="likelihood",
        var=logp(x=x_z, t_x=t_x_z, T=T, x_zero=x_zero_z),
    )
```

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Model Parameters

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_52_0.svg){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Effect in Parameters

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_59_0.png){fig-align="center"}

- Recall $\lambda \sim \text{Gamma}(r, \alpha)$, which has expected value $r/\alpha$.
- Hence, as $g_1 < 0$,  then $\alpha(z=1) > \alpha(z=0)$ which is consistent with the data generation process where $z = 1$ implied a lower frequency.

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Hierarchical BG/NBD Model - Data

```{.python}
groups = ["g1", "g2", "g3", "g4"]

data_df["group"] = rng.choice(
    a=groups, p=[0.45, 0.35, 0.15, 0.05], size=n_obs
)
```

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_66_0.png){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Hierarchical BG/NBD Model Structure

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_68_0.svg){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Hierarchical BG/NBD Model Results

![](berlin_bayesians_btyd_files/images/bg_nbd_pymc_files/bg_nbd_pymc_74_0.png){fig-align="center"}

::: footer
See [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
:::

## Bayesian BG/NBD Model

It opens many posibilities and oportunities!

- Time-Invariant Covariates
- Hierarchical Models
- ...

## A [sucessor package](https://github.com/ColtAllen/btyd) of `lifetimes`

![](berlin_bayesians_btyd_files/images/btyd_github.png){fig-align="center"}

Contributors needed!

## References {.smaller}

### Blog Posts

- [BG/NBD Model in PyMC](https://juanitorduz.github.io/bg_nbd_pymc/)
- [Gamma-Gamma Model of Monetary Value in PyMC](https://juanitorduz.github.io/gamma_gamma_pymc/)

### Papers

- [Probability Models for Customer-Base Analysis](https://www.brucehardie.com/talks/ho_cba_tut_art_09.pdf)
- [Counting Your Customers: Who Are They and What Will They Do Next?](https://www.jstor.org/stable/2631608)
- [“Counting Your Customers” the Easy Way: An Alternative to the Pareto/NBD Model](http://brucehardie.com/papers/018/fader_et_al_mksc_05.pdf)
- [Computing P(alive) Using the BG/NBD Model](https://brucehardie.com/notes/021/palive_for_BGNBD.pdf)

### Videos

- [New Perspectives on CLV and E-Commerce Buying Patterns, Peter Fader](https://www.youtube.com/watch?v=guj2gVEEx4s&t=1s)

## References

### Software

#### Python

- [`lifetimes`](https://github.com/CamDavidsonPilon/lifetimes)
- A sucessor package [`btyd`](https://github.com/ColtAllen/btyd) of `lifetimes`.
- [PyMC](https://docs.pymc.io/)

#### R

- [`BTYD`](https://cran.r-project.org/web/packages/BTYD/index.html)
- [`BTYDplus`](https://cran.r-project.org/web/packages/BTYDplus/index.html)

## Thank you!

[juanitorduz.github.io](https://juanitorduz.github.io/)

![](berlin_bayesians_btyd_files/images/juanitorduz.png){fig-align="center"}