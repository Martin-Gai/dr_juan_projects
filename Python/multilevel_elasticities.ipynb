{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Elasticities for a Single SKU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preliz as pz\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from pydantic import BaseModel, Field, model_validator, field_validator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed: int = sum(map(ord, \"multilevel_elasticities_single_sku\"))\n",
    "rng: np.random.Generator = np.random.default_rng(seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Generating Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sku(BaseModel):\n",
    "    id: int = Field(..., ge=0)\n",
    "    prices: NDArray[np.float_]\n",
    "    quantities: NDArray[np.float_]\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @field_validator(\"prices\", \"quantities\")\n",
    "    def validate_gt_0(cls, value):\n",
    "        if (value <= 0).any():\n",
    "            raise ValueError(\"prices and quantities must be positive\")\n",
    "        return value\n",
    "\n",
    "    @field_validator(\"prices\", \"quantities\")\n",
    "    def validate_size_gt_0(cls, value):\n",
    "        if value.size == 0:\n",
    "            raise ValueError(\"prices and quantities must have at least one element\")\n",
    "        return value\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    def validate_sizes(cls, values):\n",
    "        if values[\"prices\"].size != values[\"quantities\"].size:\n",
    "            raise ValueError(\"prices and quantities must have the same size\")\n",
    "        return values\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(\n",
    "            data={\n",
    "                \"item_id\": self.id,\n",
    "                \"price\": self.prices,\n",
    "                \"quantities\": self.quantities,\n",
    "                \"time_step\": np.arange(self.prices.size)[::-1],\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class Store(BaseModel):\n",
    "    id: int = Field(..., ge=0)\n",
    "    items: list[Sku] = Field(..., min_items=1)\n",
    "\n",
    "    @field_validator(\"items\")\n",
    "    def validate_item_ids(cls, value):\n",
    "        if len({item.id for item in value}) != len(value):\n",
    "            raise ValueError(\"items must have unique ids\")\n",
    "        return value\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        df = pd.concat([item.to_dataframe() for item in self.items], axis=0)\n",
    "        df[\"store_id\"] = self.id\n",
    "        df[\"region_store_id\"] = f\"r-{self.id}_s-\" + df[\"store_id\"].astype(str)\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "class Region(BaseModel):\n",
    "    id: int = Field(..., ge=0)\n",
    "    stores: list[Store] = Field(..., min_items=1)\n",
    "    median_income: float = Field(..., gt=0)  # Z_j\n",
    "\n",
    "    @field_validator(\"stores\")\n",
    "    def validate_store_ids(cls, value):\n",
    "        if len({store.id for store in value}) != len(value):\n",
    "            raise ValueError(\"stores must have unique ids\")\n",
    "        return value\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        df = pd.concat([store.to_dataframe() for store in self.stores], axis=0)\n",
    "        df[\"region_id\"] = self.id\n",
    "        df[\"median_income\"] = self.median_income\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "class Market(BaseModel):\n",
    "    regions: list[Region] = Field(..., min_items=1)\n",
    "\n",
    "    @field_validator(\"regions\")\n",
    "    def validate_region_ids(cls, value):\n",
    "        if len({region.id for region in value}) != len(value):\n",
    "            raise ValueError(\"regions must have unique ids\")\n",
    "        return value\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        df = pd.concat([region.to_dataframe() for region in self.regions], axis=0)\n",
    "        return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generating Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionConfig(BaseModel):\n",
    "    intercept: float\n",
    "    slope: float\n",
    "    sigma: float = Field(..., gt=0)\n",
    "\n",
    "\n",
    "class MultiLevelElasticitiesDataGenerator(BaseModel):\n",
    "    rng: np.random.Generator\n",
    "    n_regions: int = Field(..., gt=0)\n",
    "    time_range_mu: float = Field(..., gt=0)\n",
    "    time_range_sigma: float = Field(..., gt=0)\n",
    "    n_stores_per_region_mu: float = Field(..., gt=0)\n",
    "    n_stores_per_region_sigma: float = Field(..., gt=0)\n",
    "    median_income_per_region_mu: float = Field(..., gt=0)\n",
    "    median_income_per_region_sigma: float = Field(..., gt=0)\n",
    "    intercepts_lr_config: LinearRegressionConfig\n",
    "    slopes_lr_config: LinearRegressionConfig\n",
    "    price_mu: float = Field(..., gt=0)\n",
    "    price_sigma: float = Field(..., gt=0)\n",
    "    epsilon: float = Field(..., gt=0)\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_n_stores_per_region_draws(self) -> NDArray:\n",
    "        n_stores_per_region_dist = pm.NegativeBinomial.dist(\n",
    "            mu=self.n_stores_per_region_mu, alpha=self.n_stores_per_region_sigma\n",
    "        )\n",
    "        n_stores_per_region_draws = pm.draw(\n",
    "            n_stores_per_region_dist, draws=self.n_regions, random_seed=self.rng\n",
    "        )\n",
    "        return n_stores_per_region_draws + 2\n",
    "\n",
    "    def get_median_income_per_region_draws(self) -> NDArray:\n",
    "        median_income_per_region_dist = pm.Gamma.dist(\n",
    "            mu=self.median_income_per_region_mu,\n",
    "            sigma=self.median_income_per_region_sigma,\n",
    "        )\n",
    "        median_income_per_region_draws = pm.draw(\n",
    "            median_income_per_region_dist, draws=self.n_regions, random_seed=self.rng\n",
    "        )\n",
    "        return median_income_per_region_draws + 1\n",
    "\n",
    "    def get_store_time_range(self) -> int:\n",
    "        time_range_dist = pm.NegativeBinomial.dist(\n",
    "            mu=self.time_range_mu, alpha=self.time_range_sigma\n",
    "        )\n",
    "        time_range_samples = pm.draw(\n",
    "            vars=time_range_dist, draws=1, random_seed=self.rng\n",
    "        ).item()\n",
    "        return time_range_samples + 2\n",
    "\n",
    "    def get_alpha_j_samples(\n",
    "        self, median_income_per_region: float, store_time_range: int\n",
    "    ) -> NDArray:\n",
    "        alpha_j_dist = pm.Normal.dist(\n",
    "            mu=self.intercepts_lr_config.intercept\n",
    "            + self.intercepts_lr_config.slope * median_income_per_region,\n",
    "            sigma=self.intercepts_lr_config.sigma,\n",
    "        )\n",
    "        return pm.draw(alpha_j_dist, draws=store_time_range, random_seed=self.rng)\n",
    "\n",
    "    def get_beta_j_samples(\n",
    "        self, median_income_per_region: float, store_time_range: int\n",
    "    ) -> NDArray:\n",
    "        beta_j_dist = pm.Normal.dist(\n",
    "            mu=self.slopes_lr_config.intercept\n",
    "            + self.slopes_lr_config.slope * median_income_per_region,\n",
    "            sigma=self.slopes_lr_config.sigma,\n",
    "        )\n",
    "        return pm.draw(beta_j_dist, draws=store_time_range, random_seed=self.rng)\n",
    "\n",
    "    def get_prices_samples(self, store_time_range: int) -> NDArray:\n",
    "        price_dist = pm.Gamma.dist(\n",
    "            mu=self.price_mu,\n",
    "            sigma=self.price_sigma,\n",
    "        )\n",
    "        return pm.draw(price_dist, draws=store_time_range, random_seed=self.rng)\n",
    "\n",
    "    def get_quantities_samples(\n",
    "        self, alpha_j_samples, beta_j_samples, prices_samples\n",
    "    ) -> NDArray:\n",
    "        log_quantities_dist = pm.Normal.dist(\n",
    "            mu=alpha_j_samples + beta_j_samples * np.log(prices_samples),\n",
    "            sigma=self.epsilon,\n",
    "        )\n",
    "        log_quantities_samples = pm.draw(\n",
    "            log_quantities_dist, draws=1, random_seed=self.rng\n",
    "        )\n",
    "        return np.exp(log_quantities_samples)\n",
    "\n",
    "    def create_store(self, id: int, median_income_per_region: float) -> Store:\n",
    "        store_time_range = self.get_store_time_range()\n",
    "        alpha_j_samples = self.get_alpha_j_samples(\n",
    "            median_income_per_region=median_income_per_region,\n",
    "            store_time_range=store_time_range,\n",
    "        )\n",
    "        beta_j_samples = self.get_beta_j_samples(\n",
    "            median_income_per_region=median_income_per_region,\n",
    "            store_time_range=store_time_range,\n",
    "        )\n",
    "        prices_samples = self.get_prices_samples(store_time_range=store_time_range)\n",
    "        quantities_samples = self.get_quantities_samples(\n",
    "            alpha_j_samples=alpha_j_samples,\n",
    "            beta_j_samples=beta_j_samples,\n",
    "            prices_samples=prices_samples,\n",
    "        )\n",
    "        return Store(\n",
    "            id=id,\n",
    "            items=[Sku(id=0, prices=prices_samples, quantities=quantities_samples)],\n",
    "        )\n",
    "\n",
    "    def create_region(\n",
    "        self, id: int, n_stores_per_region: int, median_income_per_region: float\n",
    "    ) -> Region:\n",
    "        stores: list[Store] = [\n",
    "            self.create_store(id=i, median_income_per_region=median_income_per_region)\n",
    "            for i in range(n_stores_per_region)\n",
    "        ]\n",
    "        return Region(id=id, stores=stores, median_income=median_income_per_region)\n",
    "\n",
    "    def run(self) -> Market:\n",
    "        n_stores_per_region_draws = self.get_n_stores_per_region_draws()\n",
    "        median_income_per_region_draws = self.get_median_income_per_region_draws()\n",
    "\n",
    "        regions: list[Region] = [\n",
    "            self.create_region(\n",
    "                id=j,\n",
    "                n_stores_per_region=n_stores_per_region_draws[j],\n",
    "                median_income_per_region=median_income_per_region_draws[j],\n",
    "            )\n",
    "            for j in tqdm(range(self.n_regions))\n",
    "        ]\n",
    "\n",
    "        return Market(regions=regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = MultiLevelElasticitiesDataGenerator(\n",
    "    rng=rng,\n",
    "    n_regions=8,\n",
    "    time_range_mu=20,\n",
    "    time_range_sigma=5,\n",
    "    n_stores_per_region_mu=16,\n",
    "    n_stores_per_region_sigma=2,\n",
    "    median_income_per_region_mu=5,\n",
    "    median_income_per_region_sigma=2,\n",
    "    intercepts_lr_config=LinearRegressionConfig(intercept=1, slope=0.3, sigma=0.02),\n",
    "    slopes_lr_config=LinearRegressionConfig(intercept=-0.1, slope=-0.6, sigma=0.02),\n",
    "    price_mu=1.5,\n",
    "    price_sigma=0.25,\n",
    "    epsilon=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = data_generator.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_df = market.to_dataframe()\n",
    "\n",
    "market_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_df = market_df.assign(\n",
    "    log_price=lambda x: np.log(x[\"price\"]),\n",
    "    log_quantities=lambda x: np.log(x[\"quantities\"]),\n",
    "    region_id=lambda x: x[\"region_id\"].astype(\"category\"),\n",
    "    region_store_id=lambda x: x[\"region_store_id\"].astype(\"category\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=market_df,\n",
    "    x=\"price\",\n",
    "    y=\"quantities\",\n",
    "    kind=\"scatter\",\n",
    "    col=\"region_id\",\n",
    "    col_wrap=4,\n",
    "    hue=\"region_id\",\n",
    "    facet_kws={\"sharex\": True, \"sharey\": True},\n",
    ")\n",
    "legend = g.legend\n",
    "legend.set_title(title=\"Region ID\", prop={\"size\": 10})\n",
    "g.fig.suptitle(\"Price vs Quantities by Region\", y=1.05, fontsize=18, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(\n",
    "    data=market_df,\n",
    "    x=\"log_price\",\n",
    "    y=\"log_quantities\",\n",
    "    hue=\"region_id\",\n",
    "    height=8,\n",
    "    aspect=1.2,\n",
    "    scatter=False,\n",
    ")\n",
    "g.set_axis_labels(x_var=\"Log Price\", y_var=\"Log quantities\")\n",
    "legend = g.legend\n",
    "legend.set_title(title=\"Region ID\", prop={\"size\": 10})\n",
    "g.fig.suptitle(\n",
    "    \"Log Price vs Log Quantities by Region\", y=1.05, fontsize=18, fontweight=\"bold\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "(\n",
    "    market_df.groupby(\"region_id\", as_index=False)\n",
    "    .agg({\"median_income\": np.mean})\n",
    "    .pipe((sns.barplot, \"data\"), x=\"region_id\", y=\"median_income\", ax=ax)\n",
    ")\n",
    "ax.set(xlabel=\"Region ID\", ylabel=\"Median Income\")\n",
    "ax.set_title(label=\"Median Income by Region\", fontsize=18, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    data=market_df.query(\"region_id == 6\").assign(\n",
    "        store_id=lambda x: x[\"store_id\"].astype(\"category\")\n",
    "    ),\n",
    "    x=\"time_step\",\n",
    "    y=\"price\",\n",
    "    hue=\"store_id\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.invert_xaxis()\n",
    "ax.legend(\n",
    "    title=\"Store ID\", title_fontsize=14, loc=\"center left\", bbox_to_anchor=(1, 0.5)\n",
    ")\n",
    "ax.set(xlabel=\"Time Step\", ylabel=\"Price\")\n",
    "ax.set_title(label=\"Price by Store in Region 6\", fontsize=18, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Multilevel Elasticities Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = market_df.index.to_numpy()\n",
    "price = market_df[\"price\"].to_numpy()\n",
    "log_price = market_df[\"log_price\"].to_numpy()\n",
    "quantities = market_df[\"quantities\"].to_numpy()\n",
    "log_quantities = market_df[\"log_quantities\"].to_numpy()\n",
    "median_income_idx, median_income = market_df[\"median_income\"].factorize(sort=True)\n",
    "store_idx, store = market_df[\"region_store_id\"].factorize(sort=True)\n",
    "region_idx, region = market_df[\"region_id\"].factorize(sort=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"store\": store, \"region\": region, \"obs\": obs}\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "    # --- Priors ---\n",
    "\n",
    "    alpha_j_intercept = pm.Normal(name=\"alpha_j_intercept\", mu=0, sigma=1)\n",
    "    alpha_j_slope = pm.Normal(name=\"alpha_j_slope\", mu=0, sigma=1)\n",
    "    sigma_alpha = pm.Exponential(name=\"sigma_alpha\", lam=1 / 0.1)\n",
    "    z_alpha_j = pm.Normal(name=\"z_alpha_j\", mu=0, sigma=1, dims=\"region\")\n",
    "\n",
    "    beta_j_intercept = pm.Normal(name=\"beta_j_intercept\", mu=0, sigma=1)\n",
    "    beta_j_slope = pm.Normal(name=\"beta_j_slope\", mu=0, sigma=1)\n",
    "    sigma_beta = pm.Exponential(name=\"sigma_beta\", lam=1 / 0.1)\n",
    "    z_beta_j = pm.Normal(name=\"z_beta_j\", mu=0, sigma=1, dims=\"region\")\n",
    "\n",
    "    sigma = pm.Exponential(name=\"sigma\", lam=1 / 0.5)\n",
    "\n",
    "    # --- Parametrization ---\n",
    "\n",
    "    alpha_j_mu = pm.Deterministic(\n",
    "        name=\"alpha_j_mu\",\n",
    "        var=alpha_j_intercept + alpha_j_slope * median_income.to_numpy(),\n",
    "        dims=\"region\",\n",
    "    )\n",
    "    alpha_j_sigma = pm.Deterministic(\n",
    "        name=\"alpha_j_sigma\", var=sigma_alpha * z_alpha_j, dims=\"region\"\n",
    "    )\n",
    "    alpha_j = pm.Deterministic(\n",
    "        name=\"alpha_j\",\n",
    "        var=alpha_j_mu + alpha_j_sigma,\n",
    "        dims=\"region\",\n",
    "    )\n",
    "\n",
    "    beta_j_mu = pm.Deterministic(\n",
    "        name=\"beta_j_mu\",\n",
    "        var=beta_j_intercept + beta_j_slope * median_income.to_numpy(),\n",
    "        dims=\"region\",\n",
    "    )\n",
    "    beta_j_sigma = pm.Deterministic(\n",
    "        name=\"beta_j_sigma\", var=sigma_beta * z_beta_j, dims=\"region\"\n",
    "    )\n",
    "    beta_j = pm.Deterministic(\n",
    "        name=\"beta_j\",\n",
    "        var=beta_j_mu + beta_j_sigma,\n",
    "        dims=\"region\",\n",
    "    )\n",
    "\n",
    "    alpha = pm.Deterministic(name=\"alpha\", var=alpha_j[region_idx], dims=\"obs\")\n",
    "    beta = pm.Deterministic(name=\"beta\", var=beta_j[region_idx], dims=\"obs\")\n",
    "\n",
    "    mu = pm.Deterministic(name=\"mu\", var=alpha + beta * log_price, dims=\"obs\")\n",
    "\n",
    "    # --- Likelihood ---\n",
    "\n",
    "    pm.Normal(\n",
    "        name=\"likelihood\", mu=mu, sigma=sigma, observed=log_quantities, dims=\"obs\"\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata = pm.sample(\n",
    "        target_accept=0.95,\n",
    "        draws=5_000,\n",
    "        chains=5,\n",
    "        nuts_sampler=\"numpyro\",\n",
    "        random_seed=rng,\n",
    "    )\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace=idata, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata[\"sample_stats\"][\"diverging\"].sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\n",
    "    \"alpha_j_intercept\",\n",
    "    \"alpha_j_slope\",\n",
    "    \"beta_j_intercept\",\n",
    "    \"beta_j_slope\",\n",
    "    \"alpha_j\",\n",
    "    \"beta_j\",\n",
    "    \"sigma\",\n",
    "]\n",
    "\n",
    "az.summary(data=idata, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    data=idata,\n",
    "    var_names=var_names,\n",
    "    lines=[\n",
    "        (\"alpha_j_intercept\", {}, data_generator.intercepts_lr_config.intercept),\n",
    "        (\"alpha_j_slope\", {}, data_generator.intercepts_lr_config.slope),\n",
    "        (\"beta_j_intercept\", {}, data_generator.slopes_lr_config.intercept),\n",
    "        (\"beta_j_slope\", {}, data_generator.slopes_lr_config.slope),\n",
    "        (\"sigma\", {}, data_generator.epsilon),\n",
    "    ],\n",
    "    compact=True,\n",
    "    # kind=\"rank_bars\",\n",
    "    backend_kwargs={\"figsize\": (12, 15), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Model - Trace\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(\n",
    "    data=idata,\n",
    "    var_names=[\n",
    "        \"alpha_j_intercept\",\n",
    "        \"alpha_j_slope\",\n",
    "        \"beta_j_intercept\",\n",
    "        \"beta_j_slope\",\n",
    "    ],\n",
    "    figsize=(7, 7),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    data=idata,\n",
    "    var_names=[\"beta_j\"],\n",
    "    combined=True,\n",
    "    figsize=(6, 4),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = az.plot_ppc(\n",
    "#     data=posterior_predictive,\n",
    "#     observed_rug=True,\n",
    "#     random_seed=seed,\n",
    "# )\n",
    "# ax.set(\n",
    "#     title=\"Posterior Predictive Check\",\n",
    "#     xlabel=\"likelihood\",\n",
    "#     # xlim=(-0.5, 1.5),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel Model with Correlated Random Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensor.tensor as pt\n",
    "\n",
    "# https://tomicapretto.github.io/posts/2022-06-12_lkj-prior/#model-3-correlated-priors-with-lkjcorr.\n",
    "\n",
    "coords = {\n",
    "    \"store\": store,\n",
    "    \"region\": region,\n",
    "    \"obs\": obs,\n",
    "    \"effect\": [\"intercept\", \"slope\"],\n",
    "}\n",
    "\n",
    "with pm.Model(coords=coords) as model_cov:\n",
    "    alpha_j_intercept = pm.Normal(name=\"alpha_j_intercept\", mu=0, sigma=1)\n",
    "\n",
    "    beta_j_intercept = pm.Normal(name=\"beta_j_intercept\", mu=0, sigma=1)\n",
    "\n",
    "    sd_dist = pm.HalfNormal.dist(sigma=0.01, shape=2)\n",
    "    chol, corr, sigmas = pm.LKJCholeskyCov(name=\"chol_cov\", eta=2, n=2, sd_dist=sd_dist)\n",
    "\n",
    "    sigma = pm.Exponential(name=\"sigma\", lam=1 / 0.5)\n",
    "\n",
    "    z_slopes = pm.Normal(name=\"z_slopes\", mu=0, sigma=1, dims=(\"effect\", \"region\"))\n",
    "    slopes = pm.Deterministic(\n",
    "        name=\"w\", var=pt.dot(chol, z_slopes).T, dims=(\"region\", \"effect\")\n",
    "    )\n",
    "\n",
    "    alpha_j_slope = pm.Deterministic(\n",
    "        name=\"alpha_j_slope\", var=slopes[:, 0], dims=\"region\"\n",
    "    )\n",
    "\n",
    "    beta_j_slope = pm.Deterministic(\n",
    "        name=\"beta_j_slope\", var=slopes[:, 1], dims=\"region\"\n",
    "    )\n",
    "\n",
    "    alpha_j = pm.Deterministic(\n",
    "        name=\"alpha_j\",\n",
    "        var=alpha_j_intercept + alpha_j_slope * median_income.to_numpy(),\n",
    "        dims=\"region\",\n",
    "    )\n",
    "\n",
    "    beta_j = pm.Deterministic(\n",
    "        name=\"beta_j\",\n",
    "        var=beta_j_intercept + beta_j_slope * median_income.to_numpy(),\n",
    "        dims=\"region\",\n",
    "    )\n",
    "\n",
    "    alpha = pm.Deterministic(name=\"alpha\", var=alpha_j[region_idx], dims=\"obs\")\n",
    "    beta = pm.Deterministic(name=\"beta\", var=beta_j[region_idx], dims=\"obs\")\n",
    "\n",
    "    mu = pm.Deterministic(name=\"mu\", var=alpha + beta * log_price, dims=\"obs\")\n",
    "\n",
    "    # --- Likelihood ---\n",
    "\n",
    "    pm.Normal(\n",
    "        name=\"likelihood\", mu=mu, sigma=sigma, observed=log_quantities, dims=\"obs\"\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(model=model_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_cov:\n",
    "    idata_cov = pm.sample(\n",
    "        target_accept=0.90,\n",
    "        draws=5_000,\n",
    "        chains=5,\n",
    "        nuts_sampler=\"numpyro\",\n",
    "        random_seed=rng,\n",
    "    )\n",
    "    posterior_predictive_cov = pm.sample_posterior_predictive(\n",
    "        trace=idata_cov, random_seed=rng\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_cov[\"sample_stats\"][\"diverging\"].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\n",
    "    \"alpha_j_intercept\",\n",
    "    # \"alpha_j_slope\",\n",
    "    \"beta_j_intercept\",\n",
    "    # \"beta_j_slope\",\n",
    "    \"slopes\",\n",
    "    \"alpha_j\",\n",
    "    \"beta_j\",\n",
    "    \"sigma\",\n",
    "]\n",
    "\n",
    "az.summary(data=idata_cov, var_names=var_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    data=idata_cov,\n",
    "    var_names=var_names,\n",
    "    lines=[\n",
    "        (\"alpha_j_intercept\", {}, data_generator.intercepts_lr_config.intercept),\n",
    "        (\"alpha_j_slope\", {}, data_generator.intercepts_lr_config.slope),\n",
    "        (\"beta_j_intercept\", {}, data_generator.slopes_lr_config.intercept),\n",
    "        (\"beta_j_slope\", {}, data_generator.slopes_lr_config.slope),\n",
    "        (\"sigma\", {}, data_generator.epsilon),\n",
    "    ],\n",
    "    compact=True,\n",
    "    # kind=\"rank_bars\",\n",
    "    backend_kwargs={\"figsize\": (12, 15), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Model - Trace\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(data=[idata, idata_cov], var_names=[\"alpha_j\"], combined=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(data=[idata, idata_cov], var_names=[\"beta_j\"], combined=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "website_projects-1IZj_WTw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
