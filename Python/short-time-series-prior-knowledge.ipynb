{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Short Time Series with Prior Knowledge in PyMC\n",
    "\n",
    "In this notebook I want to reproduce in [PyMC](https://github.com/pymc-devs/pymc) the methodology described in the amazing blog post [Modeling Short Time Series with Prior Knowledge](https://minimizeregret.com/short-time-series-prior-knowledge) by [Tim Radtke](https://minimizeregret.com/about/) to forecast short time series using *bayesian transfer learning*. The main idea is to transfer information (e.g. long term seasonality) from a long time series to a short time series via prior distributions. Tim's blog post treats a very concrete example where all the concepts become very concrete. The challenge of the example is to generate long term forecast for a short time series of bike sales data. Specifically, the input sales data consists of three months of daily data and the objective is to generate at least a two years forecast. In general this is very hard to to with commonly available methods (as we will show below) due the fact we do not have enough historical data to capture seasonal patterns. For this concrete example, we do expect to have a strong yearly seasonal pattern as bike sales are usually much higher during summer than in winter. Hence, we could use temperature as a proxy for this seasonal pattern. However, as mentioned above, we can not simply try to use such data in a model with just 3 months of daily data ... ¯\\\\_(ツ)_/¯ ... **Here s the elegant trick**: First, fit a model on long past historical temperature data through [Fourier modes](https://en.wikipedia.org/wiki/Fourier_series) (as in Facebook's [Prophet](https://facebook.github.io/prophet/) model). Then use the posterior means and standard deviations of each Fourier mode as the prior distribution for the sales short time series $y_t$. For the later model we use a [negative binomial distribution](https://en.wikipedia.org/wiki/Negative_binomial_distribution) as the likelihood function (as we are modeling count data, i.e. the number of sales) and model the mean $\\mu_t$ through three main components:\n",
    "\n",
    "1. A *seasonal component* which consists of Fourier modes with the specified priors, dummy variables to model the weekly seasonality and a mild trend component.\n",
    "2. We use an autoregressive term $\\mu_{t -1}$ on the mean itself.\n",
    "3. An autoregressive term $y_{t - 1}$ from the input sales data.\n",
    "\n",
    "By combining the the long term seasonality learned in the temperature model in this way we can adapt it to match the scale of the sales data. We will describe the full model specification below.\n",
    "\n",
    " I was fortunate to see [Tim's talk](https://minimizeregret.com/post/2019/06/16/satrday-berlin-presentation/) about the subject back in 2019 during the [satRdays](https://berlin2019.satrdays.org/) Berlin conference (where I also gave a talk on [Remedies for Severe Class Imbalance](https://juanitorduz.github.io/class_imbalance/)). I remember listening to such great presentation ant thinking *Wow! This is a fantastic idea!* At that time I was not able to follow the modeling strategy 100%, but I kept the idea in mind. Since then, I have been faced a couple of times to the challenge of forecasting short time series where there is an expected seasonal pattern but not enough historical data. Of course, when there are many time series, the problem can be tackled using probabilistic forecasting as well (see for example [deepAR](https://arxiv.org/abs/1704.04110?context=stat.ML)). However, the strategy presented on Tim's blog post is very elegant and can serve situations where the number of time series is small (which is often the case in certain domains, e.g. marketing). Hence, I decided to try it out in PyMC! Moreover, while trying to reproduce this work I also learned some very useful things on the side:\n",
    "\n",
    "- The particular models (which we describe below) to perform the transfer learning are very interesting (specially the local level model) and I can see similar variations being applicable in many real world problems.\n",
    "- Learn to read [Stan](https://mc-stan.org/) code and understand how it works. This is because the code is provided in [R](https://www.r-project.org/) and the model is sampled using [Stan](https://mc-stan.org/). Please find the code of the blog post [here](https://github.com/timradtke/short-time-series) (kudos to Tim for sharing it and making the results fully reproducible!).\n",
    "- Learn how to use [`aesara.scan`](https://aesara.readthedocs.io/en/latest/library/scan.html) to run loops efficiently inside a PyMC model. I must admit that learning how [`aesara.scan`](https://aesara.readthedocs.io/en/latest/library/scan.html)  works was not very easy and I really had to work a concrete example and carefully read documentation to get it work. I still need some more practice but I have a much better intuition now. I share some findings and extended explanations on an appendix at the end of this notebook.\n",
    "\n",
    "I **strongly recommend to read Tim's original blog post** [Modeling Short Time Series with Prior Knowledge](https://minimizeregret.com/short-time-series-prior-knowledge) first to enjoy a clear understanding of the problem and the underlying ideas. The purpose of this notebook is mainly to reproduce his results (and the details behind the PyMC code) and not to give a detailed explanation of the model, specially the remarkable prior distributions analysis done by Tim.\n",
    "\n",
    "*For the experienced readers:* if you have know a better way to re-write or optimize this PyMC implementation I would love to hear about it. The time it takes to sample is comparable to the time it takes to run the Stan code through R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aesara\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext rich\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "We get the data from the original blog post repository [github.com/timradtke/short-time-series](https://github.com/timradtke/short-time-series). For the purpose of this notebook, I already combined (outer join on date) the sales and temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../data/sales.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "Let us start by  looking into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 6), sharex=True, sharey=False, layout=\"constrained\")\n",
    "sns.lineplot(x=\"date\", y=\"sales\", data=raw_df, color=\"black\", ax=ax[0])\n",
    "sns.lineplot(x=\"date\", y=\"temp\", data=raw_df, color=\"C0\", ax=ax[1])\n",
    "ax[0].set(title=\"Sales\")\n",
    "ax[1].set(title=\"Temperature\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"sales.notnull() and temp.notnull()\"\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 6), sharex=True, sharey=False, layout=\"constrained\")\n",
    "sns.lineplot(x=\"date\", y=\"sales\", data=raw_df.query(mask), color=\"black\", ax=ax[0])\n",
    "sns.lineplot(x=\"date\", y=\"temp\", data=raw_df.query(mask), color=\"C0\", ax=ax[1])\n",
    "ax[0].set(title=\"Sales\")\n",
    "ax[1].set(title=\"Temperature\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    raw_df.query(\"temp.notnull()\")\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    "    .eval(\n",
    "        \"\"\"\n",
    "        temp_scaled = temp - temp.min()\n",
    "        trend = (sales.index - 273 + 1) / 365.25\n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "train_test_date = pd.to_datetime(\"'2013-10-15'\")\n",
    "\n",
    "df_train = df.query(\"date < @train_test_date & sales.notnull()\")\n",
    "df_test = df.query(\"date >= @train_test_date\")\n",
    "\n",
    "n_train = df_train.shape[0]\n",
    "n_test = df_test.shape[0]\n",
    "n = n_test + n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=\"date\", y=\"sales\", data=df_train, color=\"black\", marker=\"o\", ax=ax)\n",
    "ax.set(title=\"Sales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_train,\n",
    "    marker=\"o\",\n",
    "    color=\"black\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"black\",\n",
    "    label=\"sales (train)\",\n",
    "    ax=ax,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_test,\n",
    "    marker=\"o\",\n",
    "    color=\"C1\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"C1\",\n",
    "    label=\"sales (test)\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.axvline(x=train_test_date, color=\"gray\", linestyle=\"--\", label=\"train/test split\")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "ax.set(title=\"Sales - Train/Test Split\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df[\"date\"]\n",
    "temp_scaled = df[\"temp_scaled\"]\n",
    "trend = df[\"trend\"]\n",
    "sales = df[\"sales\"]\n",
    "dayofweek_idx, dayofweek = df[\"date\"].dt.dayofweek.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = df[\"date\"].dt.dayofyear / 365.25\n",
    "n_order = 6\n",
    "\n",
    "fourier_features = pd.DataFrame(\n",
    "    {\n",
    "        f\"{func}_order_{order}\": getattr(np, func)(2 * np.pi * periods * order)\n",
    "        for order in range(1, n_order + 1)\n",
    "        for func in (\"sin\", \"cos\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\n",
    "    \"date\": date,\n",
    "    \"fourier_features\": np.arange(2 * n_order),\n",
    "}\n",
    "\n",
    "with pm.Model(coords=coords) as temp_model:\n",
    "    # --- priors ---\n",
    "    ## intercept\n",
    "    a = pm.Normal(name=\"a\", mu=0, sigma=1)\n",
    "    ## seasonality\n",
    "    b_fourier = pm.Normal(name=\"b_fourier\", mu=0, sigma=1, dims=\"fourier_features\")\n",
    "    # --- model parametrization ---\n",
    "    seasonality = pm.Deterministic(\n",
    "        \"seasonality\", pm.math.dot(b_fourier, fourier_features.to_numpy().T), dims=\"date\"\n",
    "    )\n",
    "    mu = pm.Deterministic(name=\"mu\", var= a + seasonality, dims=\"date\")\n",
    "\n",
    "    # --- likelihood ---\n",
    "    pm.Poisson(\"likelihood\", mu=pm.math.exp(mu), observed=temp_scaled, dims=\"date\")\n",
    "\n",
    "pm.model_to_graphviz(temp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with temp_model:\n",
    "    temp_prior_predictive = pm.sample_prior_predictive(samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"date\", y=\"temp_scaled\", data=df, color=\"C0\", label=\"temp (scaled)\", ax=ax\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date,\n",
    "    y=temp_prior_predictive.prior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.95,\n",
    "    color=\"gray\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 50%\", \"alpha\": 0.3},\n",
    "    ax=ax,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date,\n",
    "    y=temp_prior_predictive.prior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.5,\n",
    "    color=\"gray\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 95%\", \"alpha\": 0.5},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(title=\"Prior HDI Temperature Model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with temp_model:\n",
    "    temp_idata = pm.sampling_jax.sample_numpyro_nuts(\n",
    "        target_accept=0.9, draws=4000, chains=4\n",
    "    )\n",
    "    temp_posterior_predictive = pm.sample_posterior_predictive(trace=temp_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data=temp_idata, var_names=[\"a\", \"b_fourier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = az.plot_forest(\n",
    "    data=temp_idata,\n",
    "    var_names=[\"b_fourier\"],\n",
    "    combined=True,\n",
    "    r_hat=True,\n",
    "    ess=True,\n",
    "    figsize=(12, 6),\n",
    ")\n",
    "plt.gcf().suptitle(\n",
    "    \"Temperature Model - Posterior Distributions Fourier Modes\", fontsize=16\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"date\", y=\"temp_scaled\", data=df, color=\"C0\", label=\"temp (scaled)\", ax=ax\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date,\n",
    "    y=temp_posterior_predictive.posterior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.95,\n",
    "    color=\"gray\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 50%\", \"alpha\": 0.3},\n",
    "    ax=ax,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date,\n",
    "    y=temp_posterior_predictive.posterior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.5,\n",
    "    color=\"gray\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 95%\", \"alpha\": 0.5},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(title=\"Posterior HDI Temperature Model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = df_train[\"date\"]\n",
    "sales_train = df_train[\"sales\"]\n",
    "trend_train = df_train[\"trend\"]\n",
    "dayofweek_idx_train, dayofweek_train = df_train[\"date\"].dt.dayofweek.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_summary = az.summary(data=temp_idata, var_names=[\"b_fourier\"])\n",
    "fourier_loc = temp_model_summary[\"mean\"]\n",
    "fourier_sd = temp_model_summary[\"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_train = df_train[\"date\"].dt.dayofyear / 365.25\n",
    "n_order = 6\n",
    "\n",
    "fourier_features_train = pd.DataFrame(\n",
    "    {\n",
    "        f\"{func}_order_{order}\": getattr(np, func)(2 * np.pi * periods_train * order)\n",
    "        for order in range(1, n_order + 1)\n",
    "        for func in (\"sin\", \"cos\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\n",
    "    \"fourier_features\": np.arange(2 * n_order),\n",
    "    \"dayofweek\": dayofweek_train,\n",
    "}\n",
    "\n",
    "with pm.Model(coords=coords) as sales_model:\n",
    "    # --- data containers ---\n",
    "    sales_model.add_coord(name=\"date\", values=date_train, mutable=True)\n",
    "    trend_data = pm.MutableData(name=\"trend\", value=trend_train, dims=\"date\")\n",
    "    sales_data = pm.MutableData(name=\"sales\", value=sales_train, dims=\"date\")\n",
    "\n",
    "    # --- priors ---\n",
    "    delta = pm.Beta(name=\"delta\", alpha=1, beta=10)\n",
    "    eta = pm.Gamma(name=\"eta\", alpha=0.5, beta=10)\n",
    "    b_fourier = pm.Normal(\n",
    "        name=\"b_fourier\", mu=fourier_loc, sigma=fourier_sd, dims=\"fourier_features\"\n",
    "    )\n",
    "    b_dayofweek = pm.Normal(name=\"b_dayofweek\", mu=4, sigma=2, dims=\"dayofweek\")\n",
    "    b_trend = pm.Normal(name=\"b_trend\", mu=0.03, sigma=0.02)\n",
    "    alpha_inv = pm.Normal(name=\"mu_inv\", mu=0, sigma=0.5)\n",
    "\n",
    "    # --- model parametrization ---\n",
    "    ## parameters constraints\n",
    "    pm.Potential(name=\"constrain\", var=at.switch(eta > 1 - delta, -np.inf, 0))\n",
    "    # transferred trend and seasonality\n",
    "    fourier_contribution = pm.Deterministic(\n",
    "        name=\"fourier_contribution\",\n",
    "        var=pm.math.dot(b_fourier, fourier_features_train.to_numpy().T),\n",
    "        dims=\"date\",\n",
    "    )\n",
    "    dayofweek_contribution = pm.Deterministic(\n",
    "        name=\"dayofweek_contribution\", var=b_dayofweek[dayofweek_idx_train], dims=\"date\"\n",
    "    )\n",
    "    trend_contribution = pm.Deterministic(\n",
    "        name=\"trend_contribution\", var=b_trend * trend_data, dims=\"date\"\n",
    "    )\n",
    "    seasonality = pm.Deterministic(\n",
    "        name=\"seasonality\",\n",
    "        var=pymc.math.exp(\n",
    "            fourier_contribution + dayofweek_contribution + trend_contribution\n",
    "        ),\n",
    "        dims=\"date\",\n",
    "    )\n",
    "    ## damped dynamic mean\n",
    "    mu0 = pm.MutableData(\n",
    "        name=\"mu0\", value=np.zeros(sales_data.shape.eval()[0]), dims=\"date\"\n",
    "    )\n",
    "    mu0 = at.set_subtensor(mu0[0], sales_data[0])\n",
    "\n",
    "    def one_step(seasonality_t, sales_tm1, mu_tm1, delta, eta):\n",
    "        return (1 - delta - eta) * seasonality_t + delta * mu_tm1 + eta * sales_tm1\n",
    "\n",
    "    outputs, _ = aesara.scan(\n",
    "        fn=one_step,\n",
    "        sequences=[\n",
    "            dict(input=seasonality[1:], taps=[0]),\n",
    "            dict(input=sales_data, taps=[-1]),\n",
    "        ],\n",
    "        outputs_info=dict(initial=mu0, taps=[-1]),\n",
    "        non_sequences=[delta, eta],\n",
    "        strict=True,\n",
    "    )\n",
    "    mu = pm.Deterministic(\n",
    "        name=\"mu\", var=at.set_subtensor(mu0[1:], outputs[:, 0]), dims=\"date\"\n",
    "    )\n",
    "    alpha = pm.Deterministic(name=\"alpha\", var=1 / pm.math.sqr(alpha_inv))\n",
    "\n",
    "    # --- likelihood ---\n",
    "    pm.NegativeBinomial(\n",
    "        name=\"likelihood\", alpha=alpha, mu=mu, observed=sales_data, dims=\"date\"\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(sales_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(mu.eval())\n",
    "# plt.plot(sales_train.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha0 = at.zeros(sales_data.shape.eval()[0])\n",
    "# alpha0 = at.set_subtensor(alpha0[0], sales_data[0])\n",
    "\n",
    "# d = 0.51\n",
    "# e = 0.5\n",
    "\n",
    "# def one_step(seasonality_t, sales_tm1, alpha_tm1, delta, eta):\n",
    "#     return (1 - delta - eta) * seasonality_t + delta * alpha_tm1 + eta * sales_tm1\n",
    "\n",
    "# outputs, _ = aesara.scan(\n",
    "#         fn=one_step,\n",
    "#         sequences=[dict(input=seasonality[1:], taps=[-0]), dict(input=sales_data, taps=[-1])],\n",
    "#         outputs_info=dict(initial=alpha0, taps=[-1]),\n",
    "#         non_sequences=[delta, eta],\n",
    "#         strict=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_step(seasonality[1], sales_data[0], alpha0[0], delta, eta).eval()\n",
    "# alpha0 = at.set_subtensor(alpha0[1], one_step(seasonality[1], sales_data[0], alpha0[0], delta, eta).eval())\n",
    "# one_step(seasonality[2], sales_data[1], alpha0[1], delta, eta).eval()\n",
    "# alpha0 = at.set_subtensor(alpha0[2], one_step(seasonality[2], sales_data[1], alpha0[1], delta, eta).eval())\n",
    "# one_step(seasonality[3], sales_data[2], alpha0[2], delta, eta).eval()\n",
    "# alpha0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs[: , 0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sales_model:\n",
    "    sales_prior_predictive = pm.sample_prior_predictive(samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_train,\n",
    "    marker=\"o\",\n",
    "    color=\"black\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"black\",\n",
    "    label=\"sales (train)\",\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date_train,\n",
    "    y=sales_prior_predictive.prior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.95,\n",
    "    color=\"C0\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 50%\", \"alpha\": 0.3},\n",
    "    ax=ax,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date_train,\n",
    "    y=sales_prior_predictive.prior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.5,\n",
    "    color=\"C0\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 95%\", \"alpha\": 0.5},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(title=\"Prior HDI Sales Model\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sales_model:\n",
    "    sales_idata = pm.sample(\n",
    "        target_accept=0.95, draws=4_000, chains=4\n",
    "    )\n",
    "    sales_posterior_predictive = pm.sample_posterior_predictive(trace=sales_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"b_fourier\", \"b_dayofweek\",\"b_trend\", \"delta\", \"eta\", \"alpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data=sales_idata, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    data=sales_idata,\n",
    "    var_names=var_names,\n",
    "    compact=True,\n",
    "    kind=\"rank_bars\",\n",
    "    backend_kwargs={\"figsize\": (12, 9), \"layout\": \"constrained\"},\n",
    ")\n",
    "plt.gcf().suptitle(\"Sales Model - Trace\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_train,\n",
    "    marker=\"o\",\n",
    "    color=\"black\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"black\",\n",
    "    label=\"sales (train)\",\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date_train,\n",
    "    y=sales_posterior_predictive.posterior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.95,\n",
    "    color=\"C0\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 50%\", \"alpha\": 0.2},\n",
    "    ax=ax,\n",
    ")\n",
    "az.plot_hdi(\n",
    "    x=date_train,\n",
    "    y=sales_posterior_predictive.posterior_predictive[\"likelihood\"],\n",
    "    hdi_prob=0.5,\n",
    "    color=\"C0\",\n",
    "    smooth=False,\n",
    "    fill_kwargs={\"label\": \"HDI 95%\", \"alpha\": 0.3},\n",
    "    ax=ax,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=date_train,\n",
    "    y=sales_posterior_predictive.posterior_predictive[\"likelihood\"]\n",
    "    .stack(samples=(\"chain\", \"draw\"))\n",
    "    .mean(axis=1),\n",
    "    marker=\"o\",\n",
    "    color=\"C0\",\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"C0\",\n",
    "    label=\"mean posterior predictive\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(title=\"Posterior HDI Sales Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sales_model:\n",
    "#     pm.set_data(new_data={\"sales\": sales}, coords={\"date\": date})\n",
    "#     sales_idata.extend(\n",
    "#         other=pm.sample_posterior_predictive(\n",
    "#             trace=sales_idata,\n",
    "#             var_names=[\"likelihood\"],\n",
    "#             idata_kwargs={\"coords\": {\"date\": date}},\n",
    "#         ),\n",
    "#         join=\"right\",\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = sales_idata.posterior.stack(samples=(\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_posterior = np.exp(\n",
    "    posterior[\"b_trend\"].to_numpy()[..., None] * trend[-n:][None, ...]\n",
    "    + posterior[\"b_dayofweek\"][dayofweek_idx[-n:]].T\n",
    "    + np.tensordot(\n",
    "        a=posterior[\"b_fourier\"], b=fourier_features[-n:], axes=[[0], [1]]\n",
    "    ).reshape(-1, n)\n",
    ")\n",
    "\n",
    "seasonality_posterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_posterior = sales_posterior_predictive.posterior_predictive[\n",
    "    \"likelihood\"\n",
    "].stack(samples=(\"chain\", \"draw\")).T\n",
    "\n",
    "sales_train_posterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4000 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_posterior = np.zeros(shape=(n_samples, n))\n",
    "sales_posterior[:, :n_train] = sales_train_posterior\n",
    "sales_posterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_posterior = np.zeros(shape=(n_samples, n))\n",
    "mu_posterior[:, :n_train] = posterior[\"mu\"].T\n",
    "mu_posterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for t in tqdm(range(n_train, n)):\n",
    "    \n",
    "    mu_posterior[:, t] = (\n",
    "        ((1 - posterior[\"delta\"] - posterior[\"eta\"]) * seasonality_posterior[:, t])\n",
    "        + (posterior[\"delta\"] * mu_posterior[:, t - 1])\n",
    "        + (posterior[\"eta\"] * sales_posterior[:, t - 1])\n",
    "    )\n",
    "\n",
    "    likelihood = pm.NegativeBinomial.dist(\n",
    "        name=\"posterior_sales\", mu=mu_posterior[:, t], alpha=posterior[\"alpha\"].to_numpy()\n",
    "    )\n",
    "\n",
    "    sales_posterior[:, t] = pm.draw(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_posterior_hdi95 = az.hdi(sales_posterior, hdi_prob=0.95)\n",
    "sales_posterior_hdi50 = az.hdi(sales_posterior, hdi_prob=0.50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "ax.fill_between(\n",
    "    x=date[-n:],\n",
    "    y1=sales_posterior_hdi95[:, 0],\n",
    "    y2=sales_posterior_hdi95[:, 1],\n",
    "    color=\"C0\",\n",
    "    label=\"HDI 95%\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.fill_between(\n",
    "    x=date[-n:],\n",
    "    y1=sales_posterior_hdi50[:, 0],\n",
    "    y2=sales_posterior_hdi50[:, 1],\n",
    "    color=\"C0\",\n",
    "    label=\"HDI 50%\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_train,\n",
    "    marker=\"o\",\n",
    "    color=\"black\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"black\",\n",
    "    label=\"sales (train)\",\n",
    "    ax=ax,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"date\",\n",
    "    y=\"sales\",\n",
    "    data=df_test,\n",
    "    marker=\"o\",\n",
    "    color=\"C1\",\n",
    "    alpha=0.8,\n",
    "    markersize=4,\n",
    "    markeredgecolor=\"C1\",\n",
    "    label=\"sales (test)\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.axvline(x=train_test_date, color=\"gray\", linestyle=\"--\", label=\"train/test split\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set(title=\"Sales Model - Out of Sample Predictions\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('website_projects-1IZj_WTw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "867ba48c05011db76db56a12fb95ccd32f7ac276df8f4ae698e0d475911a6ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
